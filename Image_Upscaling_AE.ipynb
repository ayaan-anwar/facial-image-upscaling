{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFsn2qcngNs3"
   },
   "source": [
    "# <center> Image Upscaling using Sparse Denoising Autoencoders & GANs </center>\n",
    "## <center> Part-1 Autoencoder </center>\n",
    "### <center>Mohd Ayaan Anwar (2K19/CO/232) and Nakul Saroha (2K19/CO/238)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nhidd6gBgrZH"
   },
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8gKwHkx8gsJf",
    "outputId": "ee0831ce-a697-46b1-f184-e3453bb582bb"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0STs1_mGg7VE",
    "outputId": "7bbe7a9c-4e64-4bff-82db-7bd9dfde6d09"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/AI_Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JmbKfaA5hZbb"
   },
   "source": [
    "## 0.1. Fetch and Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BXcOELDchJvu",
    "outputId": "c3ca4eca-ae6f-48ed-84a1-5b1ff373c650"
   },
   "outputs": [],
   "source": [
    "!wget http://vis-www.cs.umass.edu/lfw/lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RTkaBuxIhQsQ",
    "outputId": "1fe56a16-9f0d-4482-b419-9caebdaf2eb7"
   },
   "outputs": [],
   "source": [
    "!tar -xzvf lfw.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "28lVvJDQhNCS",
    "outputId": "eb7b1b16-1d9d-4bda-b3da-3ed8dc354131"
   },
   "outputs": [],
   "source": [
    "!wget http://vis-www.cs.umass.edu/lfw/lfw-names.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5OAvtu3xhULK"
   },
   "source": [
    "## 0.2. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R12cK_Y7hjPj",
    "outputId": "01b430a5-ec3c-422c-ba16-3ae68b309ce4"
   },
   "outputs": [],
   "source": [
    "!pip install fastai --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vECBquCehM_K"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "# visualization\n",
    "from PIL import Image\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras import Model, Input, regularizers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D, Add, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "\n",
    "import torch\n",
    "from fastai.vision.all import *\n",
    "from PIL import ImageFile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split \n",
    "import pickle\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQNBitdmgsqi"
   },
   "source": [
    "# 1. EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "su0liv1dgujJ",
    "outputId": "f16427b8-7b7a-4f59-ac08-0356663a3bfc"
   },
   "outputs": [],
   "source": [
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "path = 'lfw/'\n",
    "data = ImageDataLoaders.from_folder(path, train='train',\n",
    "                                   item_tfms=Resize(256),valid_pct=0.2,\n",
    "                                   bs=64,seed=0)\n",
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "pLNtRXjRhx7E",
    "outputId": "05430be8-d26b-4389-dc9d-fa1c19aec09f"
   },
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "n0IaKy-zhz-O",
    "outputId": "b2d9c3b4-b097-4032-8880-f4c034e1cc97"
   },
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "id": "obFACHGyh3Qe",
    "outputId": "cefd4b6a-64c8-4e0f-c6e9-5ede89abf7bf"
   },
   "outputs": [],
   "source": [
    "data.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cPQlONGZh3NA",
    "outputId": "93b396fd-e7fb-4947-bdd3-51fa4e628e06"
   },
   "outputs": [],
   "source": [
    "lfw_allnames = pd.read_csv(\"lfw-names.txt\", sep='\\t', header=None, names=['name', 'images'])\n",
    "lfw_allnames.head(), lfw_allnames.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0fSMPE8h3Kd",
    "outputId": "df0b84a6-049c-499c-bacd-826ded1768cb"
   },
   "outputs": [],
   "source": [
    "print(\"Summary:\")\n",
    "print(\"There are \" + \n",
    "      str(lfw_allnames.shape[0]) + \n",
    "      \" unique celebrities in the entire dataset, of whom \" + \n",
    "      str(sum(lfw_allnames.images > 1)) + \n",
    "      \" are represented by multiple images. The entire number of images available is \" + \n",
    "      str(sum(lfw_allnames.images)) + \n",
    "      \". The most represented celebrity is \" + \n",
    "      str(lfw_allnames.iloc[lfw_allnames['images'].idxmax()][0]) + \n",
    "      \", with \" + \n",
    "      str(max(lfw_allnames.images)) + \n",
    "      \" unique images in the dataset.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X0GIwSVvh3H7",
    "outputId": "4c7777f1-d277-4c05-d5fe-76dd26109162"
   },
   "outputs": [],
   "source": [
    "image_paths = lfw_allnames.loc[lfw_allnames.index.repeat(lfw_allnames['images'])]\n",
    "image_paths['image_path'] = 1 + image_paths.groupby('name').cumcount()\n",
    "image_paths['image_path'] = image_paths.image_path.apply(lambda x: '{0:0>4}'.format(x))\n",
    "image_paths['image_path'] = image_paths.name + \"/\" + image_paths.name + \"_\" + image_paths.image_path + \".jpg\"\n",
    "image_paths = image_paths.drop(\"images\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "By4-tFSqh3FN",
    "outputId": "45119538-3fab-4ca2-9a02-3e8529ce5a15"
   },
   "outputs": [],
   "source": [
    "# verify resolution of all images is consistent\n",
    "widths = []\n",
    "heights = []\n",
    "files = image_paths.image_path\n",
    "for file in files:\n",
    "    path = \"lfw/\" + str(file)\n",
    "    im = Image.open(path)\n",
    "    widths.append(im.width)\n",
    "    heights.append(im.height)\n",
    "\n",
    "pd.DataFrame({'height':heights,'width':widths}).describe()\n",
    "\n",
    "# all 250 x 250 resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzyY5AQwiCTD"
   },
   "source": [
    "We can observe that each image is of the resolution 250x250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "r7DY6l0riEfl",
    "outputId": "7d64ec55-6be0-4480-de7a-2c28ea937572"
   },
   "outputs": [],
   "source": [
    "image_paths['name'].value_counts()[:10].plot(kind = \"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8jidQmGiHoA"
   },
   "source": [
    "We can see that there are some very well-represented figures among the top 10: generally political and generally male. This has important implications for the usefulness of this dataset in generalizations, which we consider in the conclusion. To draw this further into distinction, how many individuals are represented by a single image, compared to George W Bush's 530?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QZofv3owiEdH",
    "outputId": "6cead64a-d4a6-4f94-9396-05bf1511706e"
   },
   "outputs": [],
   "source": [
    "ind_counts = image_paths.groupby('name').count().image_path\n",
    "print(str(sum(ind_counts[ind_counts==1])) + \" individuals, which is \" +\n",
    "      str(round(100*(sum(ind_counts[ind_counts==1])/sum(ind_counts)))) +\n",
    "      \"% of the total individuals considered, are only represented by a single image in this dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOtezRmviEaz"
   },
   "source": [
    "As a sanity check, and to check the directories are all correctly connected, we visualize a sample image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "D1bDdc1NiNjF",
    "outputId": "2c43c54a-98d0-49d3-fb9b-da7b983d17d8"
   },
   "outputs": [],
   "source": [
    "im = Image.open(\"lfw/\" + str(image_paths.image_path[0]))\n",
    "plt.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "8KXbr9SmiEYf",
    "outputId": "a6d517cf-bc9f-459e-f1c8-d4257b66e2d2"
   },
   "outputs": [],
   "source": [
    "df = lfw_allnames.sort_values(by='images', ascending=False)\n",
    "fig = px.bar(df, x=\"name\", y=\"images\", color=\"images\", title=\"Person and # Images\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdXIPGJGgvMn"
   },
   "source": [
    "# 2. Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eRo2d29IC5DW",
    "outputId": "269e0643-2b0a-4c93-eaa3-fd00ba76528c"
   },
   "outputs": [],
   "source": [
    "face_images = glob.glob('lfw/**/*.jpg') #gives path\n",
    "\n",
    "print(face_images[:2], len(face_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "11rzKHxxL4fQ"
   },
   "outputs": [],
   "source": [
    "with open('face_images_path.pickle','wb') as f:\n",
    "  pickle.dump(face_images,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h5D-8Lf7EmXb"
   },
   "source": [
    "## 2.1. Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8fLkTDMLFyxE"
   },
   "outputs": [],
   "source": [
    "with open('face_images_path.pickle','rb') as f:\n",
    "  face_images = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFSzcacq0DK5"
   },
   "source": [
    "## 2.2. Randomly Sample 1200 images (1000 test + 200 validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sP9Z8I7QJq44"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "face_images = random.sample(face_images, 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPezcezAL_to",
    "outputId": "163c47ac-2545-4659-edae-be69324255fe"
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "progress = tqdm(total= len(face_images), position=0)\n",
    "def read(path):\n",
    "  img = image.load_img(path, target_size=(256,256,3))\n",
    "  img = image.img_to_array(img)\n",
    "  img = img/255.\n",
    "  progress.update(1)\n",
    "  return img\n",
    "\n",
    "p = Pool(10)\n",
    "img_array = p.map(read, face_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wZjLrTeMM-S"
   },
   "outputs": [],
   "source": [
    "with open('img_array.pickle','wb') as f:\n",
    "  pickle.dump(img_array, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6_6JYTqHMbzS",
    "outputId": "7133275e-f3b1-402e-950f-a36fde3a46e0"
   },
   "outputs": [],
   "source": [
    "len(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kn3zJMgqL7td"
   },
   "source": [
    "## 2.3. Load Train, Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRFiOTJKMeUa"
   },
   "outputs": [],
   "source": [
    "with open('img_array.pickle','rb') as f:\n",
    "  img_array = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kmse0W_aHlq9",
    "outputId": "43a713c7-1761-4977-daa1-2e17d397d988"
   },
   "outputs": [],
   "source": [
    "len(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "3PKD4q-3Mfra",
    "outputId": "7879a890-8a94-4092-9fa9-f80f088c5962"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_array[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zULFjhs_MhGi"
   },
   "outputs": [],
   "source": [
    "all_images = np.array(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bf5VF0SZGpYx",
    "outputId": "a94a6c65-e534-4a56-e0de-219230ed20a7"
   },
   "outputs": [],
   "source": [
    "all_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCEZa4kDKFRR"
   },
   "outputs": [],
   "source": [
    "train_x = all_images[:1000]\n",
    "val_x = all_images[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b7wHTujKKMGZ",
    "outputId": "aceac771-de4a-4612-ed6b-6809cec1aa15"
   },
   "outputs": [],
   "source": [
    "len(train_x), len(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9bTsqOd4NEJW"
   },
   "outputs": [],
   "source": [
    "#now we will make input images by lowering resolution without changing the size\n",
    "def pixalate_image(image, scale_percent = 25):\n",
    "  width = int(image.shape[1] * scale_percent / 100)\n",
    "  height = int(image.shape[0] * scale_percent / 100)\n",
    "  dim = (width, height)\n",
    "\n",
    "  small_image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "  \n",
    "  # scale back to original size\n",
    "  width = int(small_image.shape[1] * 100 / scale_percent)\n",
    "  height = int(small_image.shape[0] * 100 / scale_percent)\n",
    "  dim = (width, height)\n",
    "\n",
    "  low_res_image = cv2.resize(small_image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "  return low_res_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "DUF7W_TXNJEd",
    "outputId": "6befb78f-0acf-48e1-d1e1-298833c360af"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 2)\n",
    "ax[0].set_title('Original Image')\n",
    "ax[0].imshow(img_array[750])\n",
    "\n",
    "ax[1].set_title('Pixelated Image')\n",
    "ax[1].imshow(pixalate_image(img_array[750]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WJK53tLYt_nV",
    "outputId": "91f245d0-261b-470c-81cf-e895ac50229d"
   },
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "\n",
    "def display_image_in_actual_size(img, type):\n",
    "\n",
    "    dpi = mpl.rcParams['figure.dpi']\n",
    "    im_data = img\n",
    "    height, width, depth = im_data.shape\n",
    "\n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = 3*width / float(dpi), 3*height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the image.\n",
    "    ax.imshow(im_data, cmap='gray')\n",
    "    plt.title(type)\n",
    "    plt.show()\n",
    "\n",
    "display_image_in_actual_size(pixalate_image(img_array[500]), 'Pixelated')\n",
    "display_image_in_actual_size(img_array[500], 'Original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2GDfjPI8NQLf"
   },
   "outputs": [],
   "source": [
    "train_x_px = []\n",
    "\n",
    "for i in range(train_x.shape[0]):\n",
    "  temp = pixalate_image(train_x[i,:,:,:])\n",
    "  train_x_px.append(temp)\n",
    "\n",
    "train_x_px = np.array(train_x_px)\n",
    "\n",
    "\n",
    "# get low resolution images for the validation set\n",
    "val_x_px = []\n",
    "\n",
    "for i in range(val_x.shape[0]):\n",
    "  temp = pixalate_image(val_x[i,:,:,:])\n",
    "  val_x_px.append(temp)\n",
    "\n",
    "val_x_px = np.array(val_x_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "53GcJWnRwjDc",
    "outputId": "56bf6cfd-70b2-4267-a268-d87321be61aa"
   },
   "outputs": [],
   "source": [
    "train_x_px[100].shape, train_x[100].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0bLeU9rm0Xt1"
   },
   "source": [
    "# 2.4. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vHK6uc-hPTAp"
   },
   "outputs": [],
   "source": [
    "Input_img = Input(shape=(256, 256, 3))  \n",
    "    \n",
    "#encoding architecture\n",
    "x1 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(Input_img)\n",
    "x2 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x1)\n",
    "x3 = MaxPool2D(padding='same')(x2)\n",
    "\n",
    "x4 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x3)\n",
    "x5 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x4)\n",
    "x6 = MaxPool2D(padding='same')(x5)\n",
    "\n",
    "encoded = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x6)\n",
    "#encoded = Conv2D(64, (3, 3), activation='relu', padding='same')(x2)\n",
    "\n",
    "# decoding architecture\n",
    "x7 = UpSampling2D()(encoded)\n",
    "x8 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x7)\n",
    "x9 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x8)\n",
    "x10 = Add()([x5, x9])\n",
    "\n",
    "x11 = UpSampling2D()(x10)\n",
    "x12 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x11)\n",
    "x13 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x12)\n",
    "x14 = Add()([x2, x13])\n",
    "\n",
    "\n",
    "decoded = Conv2D(3, (3, 3), padding='same',activation='relu', kernel_regularizer=regularizers.l1(10e-10))(x14)\n",
    "\n",
    "autoencoder = Model(Input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GgcZj9R8Pn-s",
    "outputId": "162a57f3-2b4a-40d5-bdce-118acb656626"
   },
   "outputs": [],
   "source": [
    "autoencoder.summary()\n",
    "early_stopper = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=50, verbose=1, mode='min')\n",
    "model_checkpoint = ModelCheckpoint('AE_Models/autoencoder_checkpoint.h5',save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsxQ5PgK0n2H"
   },
   "source": [
    "## 2.5. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "utISAoE4Ptu6",
    "outputId": "975339d4-7cbb-4f6d-c4b4-f0ca6e289578"
   },
   "outputs": [],
   "source": [
    "history = autoencoder.fit(train_x_px,train_x,\n",
    "            epochs=100,\n",
    "            validation_data=(val_x_px, val_x),\n",
    "            callbacks=[early_stopper, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tXIPSpfoP4ZT"
   },
   "outputs": [],
   "source": [
    "autoencoder.save('autoencoder_batch.h5')\n",
    "# autoencoder.save('autoencoder_all.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZduyrScc0rD3"
   },
   "source": [
    "# 3. Evaluate AE (trained on 1200 images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aE5tgiUp3E7r"
   },
   "outputs": [],
   "source": [
    "def pixelate_image(image, scale_percent = 25):\n",
    "  width = int(image.shape[1] * scale_percent / 100)\n",
    "  height = int(image.shape[0] * scale_percent / 100)\n",
    "  dim = (width, height)\n",
    "\n",
    "  small_image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "  \n",
    "  # scale back to original size\n",
    "  width = int(small_image.shape[1] * 100 / scale_percent)\n",
    "  height = int(small_image.shape[0] * 100 / scale_percent)\n",
    "  dim = (width, height)\n",
    "\n",
    "  low_res_image = cv2.resize(small_image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "  return low_res_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pA2XToXS1QVt"
   },
   "outputs": [],
   "source": [
    "autoencoder = keras.models.load_model('AE_Models/autoencoder_batch.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHCSCHXHYux1"
   },
   "outputs": [],
   "source": [
    "def read(path):\n",
    "  img = image.load_img(path, target_size=(256,256,3))\n",
    "  img = image.img_to_array(img)\n",
    "  img = img/255.\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qedqjN3T1O6a"
   },
   "outputs": [],
   "source": [
    "def evaluate(img):\n",
    "    f, ax = plt.subplots(1, 2)\n",
    "    ax[0].set_title('Input Image')\n",
    "    ax[1].set_title('Output Image')\n",
    "\n",
    "    test_img = np.array(pixelate_image(img))\n",
    "    ax[0].imshow(test_img)\n",
    "    test_img = np.expand_dims(test_img, axis=0)\n",
    "    pred = autoencoder.predict(test_img)\n",
    "    pred = np.squeeze(pred, axis=0)\n",
    "    ax[1].imshow(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y32R37501g1F"
   },
   "source": [
    "## Images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "ijvfUi_X1laD",
    "outputId": "e9421bbb-d9ad-4afd-f9e5-3abe01f03f15"
   },
   "outputs": [],
   "source": [
    "evaluate(img_array[464])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "__VA4L0b1n7l",
    "outputId": "1d44b928-fc7b-414b-c32e-5ae35ad7ac54"
   },
   "outputs": [],
   "source": [
    "evaluate(img_array[600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "jRbuLWGE1rfY",
    "outputId": "2f911ccd-a709-4108-84bb-fcb1c4d75a84"
   },
   "outputs": [],
   "source": [
    "evaluate(img_array[800])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olEUzQtB1ucN"
   },
   "source": [
    "## Images NOT in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHox87y04WTG",
    "outputId": "00dbe688-0570-4317-908d-382c1d96b96f"
   },
   "outputs": [],
   "source": [
    "!ls Test_Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "PAP-QT141yzx",
    "outputId": "a945b9cc-9d11-4bb4-8268-0a75dc99cba9"
   },
   "outputs": [],
   "source": [
    "test1 = read('Test_Images/test1.jpg')\n",
    "evaluate(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "uzLnxbna1yuY",
    "outputId": "be83b37c-1cae-4527-c29f-779ab57aecbd"
   },
   "outputs": [],
   "source": [
    "test2 = read('Test_Images/test2.jpg')\n",
    "evaluate(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "x-3gXcA7NZDG",
    "outputId": "ce34ac7b-7543-4fa6-e3e4-a8611f7c299f"
   },
   "outputs": [],
   "source": [
    "test3 = read('Test_Images/test3.jpg')\n",
    "evaluate(test3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7c4SzV2mgyMU"
   },
   "source": [
    "# 4. Evaluate AE (trained on whole dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WTGCqSL62ACw"
   },
   "outputs": [],
   "source": [
    "autoencoder2 = keras.models.load_model('AE_Models/autoencoder_all.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "52X0jAoa2ACx"
   },
   "outputs": [],
   "source": [
    "def read(path):\n",
    "  img = image.load_img(path, target_size=(80,80,3))\n",
    "  img = image.img_to_array(img)\n",
    "  img = img/255.\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IxJ4030D2ACx"
   },
   "outputs": [],
   "source": [
    "def evaluate(img):\n",
    "    f, ax = plt.subplots(1, 2)\n",
    "    ax[0].set_title('Input Image')\n",
    "    ax[1].set_title('Output Image')\n",
    "    img = cv2.resize(img, (80, 80))\n",
    "    test_img = np.array(pixelate_image(img, scale_percent=40))\n",
    "    ax[0].imshow(test_img)\n",
    "    test_img = np.expand_dims(test_img, axis=0)\n",
    "    pred = autoencoder2.predict(test_img)\n",
    "    pred = np.squeeze(pred, axis=0)\n",
    "    ax[1].imshow(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEvaEb4B2ACx"
   },
   "source": [
    "## Images from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "gDBSTT1A2ACx",
    "outputId": "844a5dff-ca92-4fe3-fcd1-ed52ce01aa42"
   },
   "outputs": [],
   "source": [
    "evaluate(img_array[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "KVMf_1Tr2ACx",
    "outputId": "7725aa5c-8643-48e9-aca8-13dcbd078816"
   },
   "outputs": [],
   "source": [
    "evaluate(img_array[297])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "VlSST_cB2ACx",
    "outputId": "1a1f9a81-3b97-4542-baaf-bbcd2233d1cb"
   },
   "outputs": [],
   "source": [
    "evaluate(img_array[871])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ca18ucC82ACx"
   },
   "source": [
    "## Images NOT in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "Kl64wxfq2ACx",
    "outputId": "be40733f-3a3f-4932-ed51-5e4b4e2051ca"
   },
   "outputs": [],
   "source": [
    "test1 = read('Test_Images/test1.jpg')\n",
    "evaluate(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "BSDSCs1W2ACx",
    "outputId": "f4ed4501-1fc4-4ac3-9211-8328e700e106"
   },
   "outputs": [],
   "source": [
    "test2 = read('Test_Images/test2.jpg')\n",
    "evaluate(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "Cbtg8PJ62ACx",
    "outputId": "eac3cfa3-9620-4d4c-ed83-6a6626198708"
   },
   "outputs": [],
   "source": [
    "test3 = read('Test_Images/test3.jpg')\n",
    "evaluate(test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbV3sUYA5Jny"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Image_Upscaling_AE.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
