{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L1ZxkgLvESB2"
   },
   "source": [
    "# <center> Image Upscaling using Stacked Sparse Autoencoders & GANs </center>\n",
    "## <center> Part-2 Pix2Pix GAN </center>\n",
    "### <center>Mohd Ayaan Anwar (2K19/CO/232) and Nakul Saroha (2K19/CO/238)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jkT5dCkNZKG8"
   },
   "source": [
    "# Pix2Pix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FHukPdzJIAq5"
   },
   "source": [
    "# 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25EsVzFnIDX4"
   },
   "source": [
    "## 0.1. Set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Sl6ZC7A-Dhs",
    "outputId": "75f2dd8e-59dd-474c-db05-4a28eb6d0897"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3mWv4bKXIG2e",
    "outputId": "56f67460-01f1-415c-88d0-02344dd3526a"
   },
   "outputs": [],
   "source": [
    "%cd /content/drive/MyDrive/AI_Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WdMLWuGpZMTr"
   },
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YmzveVyCZL0h"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.models import Model\n",
    "from keras.models import Input\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Conv2DTranspose\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Concatenate\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IfHzZvRaZRUZ"
   },
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDnaECeLZQxV"
   },
   "outputs": [],
   "source": [
    "with open('img_array.pickle','rb') as f:\n",
    "    img_array = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jj6U-jz9aK_1",
    "outputId": "18a6215e-4b8e-4266-c546-d0398bcd0aee"
   },
   "outputs": [],
   "source": [
    "len(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "oHoMSh4da8_M",
    "outputId": "56d10dc7-cc17-44b3-fbf7-7efcf72a2428"
   },
   "outputs": [],
   "source": [
    "plt.imshow(img_array[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNxeX2CZbzO5"
   },
   "outputs": [],
   "source": [
    "all_images = np.array(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SmWbbZDdbzO6",
    "outputId": "caef9db1-5a23-4ef2-b06e-b37d59a60036"
   },
   "outputs": [],
   "source": [
    "all_images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEniUbg1Ey1w"
   },
   "source": [
    "# 3. Data Processing (Pixelate Image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ls9cAL8QbzO6"
   },
   "outputs": [],
   "source": [
    "train_x = all_images[:1000]\n",
    "val_x = all_images[1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s22I0Nb4bzO7",
    "outputId": "b2ae4e65-fa9e-4ae6-8fd0-168b403f0497"
   },
   "outputs": [],
   "source": [
    "len(train_x), len(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gmkWLAjKbzO7"
   },
   "outputs": [],
   "source": [
    "def pixelate_image(image, scale_percent = 25):\n",
    "    width = int(image.shape[1] * scale_percent / 100)\n",
    "    height = int(image.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "\n",
    "    small_image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    # scale back to original size\n",
    "    width = int(small_image.shape[1] * 100 / scale_percent)\n",
    "    height = int(small_image.shape[0] * 100 / scale_percent)\n",
    "    dim = (width, height)\n",
    "\n",
    "    low_res_image = cv2.resize(small_image, dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    return low_res_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y0IVnmuabzO8"
   },
   "outputs": [],
   "source": [
    "train_x_px = []\n",
    "\n",
    "for i in range(train_x.shape[0]):\n",
    "    temp = pixelate_image(train_x[i,:,:,:])\n",
    "    train_x_px.append(temp)\n",
    "\n",
    "train_x_px = np.array(train_x_px)\n",
    "\n",
    "\n",
    "# get low resolution images for the validation set\n",
    "val_x_px = []\n",
    "\n",
    "for i in range(val_x.shape[0]):\n",
    "    temp = pixelate_image(val_x[i,:,:,:])\n",
    "    val_x_px.append(temp)\n",
    "\n",
    "val_x_px = np.array(val_x_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KaneHSRibzO8"
   },
   "outputs": [],
   "source": [
    "high_reso_imgs = train_x\n",
    "low_reso_imgs = train_x_px   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NEtMbQmLbzO8",
    "outputId": "2073b2c4-b934-4701-d33f-9ddab0a45e36"
   },
   "outputs": [],
   "source": [
    "train_x.shape, train_x_px.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FPUU-O3HZXSA"
   },
   "source": [
    "# 4. Pix2Pix Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b23IYar1ZYEr"
   },
   "outputs": [],
   "source": [
    "def define_discriminator(image_shape):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# source image input\n",
    "\tin_src_image = Input(shape=image_shape)\n",
    "\t# target image input\n",
    "\tin_target_image = Input(shape=image_shape)\n",
    "\t# concatenate images channel-wise\n",
    "\tmerged = Concatenate()([in_src_image, in_target_image])\n",
    "\t# C64\n",
    "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C128\n",
    "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C256\n",
    "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# C512\n",
    "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# second last output layer\n",
    "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\td = BatchNormalization()(d)\n",
    "\td = LeakyReLU(alpha=0.2)(d)\n",
    "\t# patch output\n",
    "\td = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
    "\tpatch_out = Activation('sigmoid')(d)\n",
    "\t# define model\n",
    "\tmodel = Model([in_src_image, in_target_image], patch_out)\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n",
    "\treturn model\n",
    "\n",
    "def define_encoder_block(layer_in, n_filters, batchnorm=True):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# add downsampling layer\n",
    "\tg = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\t# conditionally add batch normalization\n",
    "\tif batchnorm:\n",
    "\t\tg = BatchNormalization()(g, training=True)\n",
    "\t# leaky relu activation\n",
    "\tg = LeakyReLU(alpha=0.2)(g)\n",
    "\treturn g\n",
    "\n",
    "def decoder_block(layer_in, skip_in, n_filters, dropout=True):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# add upsampling layer\n",
    "\tg = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n",
    "\t# add batch normalization\n",
    "\tg = BatchNormalization()(g, training=True)\n",
    "\t# conditionally add dropout\n",
    "\tif dropout:\n",
    "\t\tg = Dropout(0.5)(g, training=True)\n",
    "\t# merge with skip connection\n",
    "\tg = Concatenate()([g, skip_in])\n",
    "\t# relu activation\n",
    "\tg = Activation('relu')(g)\n",
    "\treturn g\n",
    "\n",
    "def define_generator(image_shape=(256,256,3)):\n",
    "\t# weight initialization\n",
    "\tinit = RandomNormal(stddev=0.02)\n",
    "\t# image input\n",
    "\tin_image = Input(shape=image_shape)\n",
    "\t# encoder model: C64-C128-C256-C512-C512-C512-C512-C512\n",
    "\te1 = define_encoder_block(in_image, 64, batchnorm=False)\n",
    "\te2 = define_encoder_block(e1, 128)\n",
    "\te3 = define_encoder_block(e2, 256)\n",
    "\te4 = define_encoder_block(e3, 512)\n",
    "\te5 = define_encoder_block(e4, 512)\n",
    "\te6 = define_encoder_block(e5, 512)\n",
    "\te7 = define_encoder_block(e6, 512)\n",
    "\t# bottleneck, no batch norm and relu\n",
    "\tb = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n",
    "\tb = Activation('relu')(b)\n",
    "\t# decoder model: CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
    "\td1 = decoder_block(b, e7, 512)\n",
    "\td2 = decoder_block(d1, e6, 512)\n",
    "\td3 = decoder_block(d2, e5, 512)\n",
    "\td4 = decoder_block(d3, e4, 512, dropout=False)\n",
    "\td5 = decoder_block(d4, e3, 256, dropout=False)\n",
    "\td6 = decoder_block(d5, e2, 128, dropout=False)\n",
    "\td7 = decoder_block(d6, e1, 64, dropout=False)\n",
    "\t# output\n",
    "\tg = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n",
    "\tout_image = Activation('tanh')(g)\n",
    "\t# define model\n",
    "\tmodel = Model(in_image, out_image)\n",
    "\treturn model\n",
    "\n",
    "def define_gan(g_model, d_model, image_shape):\n",
    "\t# make weights in the discriminator not trainable\n",
    "\tfor layer in d_model.layers:\n",
    "\t\tif not isinstance(layer, BatchNormalization):\n",
    "\t\t\tlayer.trainable = False\n",
    "\t# define the source image\n",
    "\tin_src = Input(shape=image_shape)\n",
    "\t# connect the source image to the generator input\n",
    "\tgen_out = g_model(in_src)\n",
    "\t# connect the source input and generator output to the discriminator input\n",
    "\tdis_out = d_model([in_src, gen_out])\n",
    "\t# src image as input, generated image and classification output\n",
    "\tmodel = Model(in_src, [dis_out, gen_out])\n",
    "\t# compile model\n",
    "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\tmodel.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "id": "g7Ov1UWLZkJZ",
    "outputId": "86a712c5-e544-4f83-b2e2-9668854eb30f"
   },
   "outputs": [],
   "source": [
    "# define image shape\n",
    "image_shape = (256,256,3)\n",
    "# define the models\n",
    "d_model = define_discriminator(image_shape)\n",
    "g_model = define_generator(image_shape)\n",
    "# define the composite model\n",
    "gan_model = define_gan(g_model, d_model, image_shape)\n",
    "# summarize the model\n",
    "gan_model.summary()\n",
    "# plot the model\n",
    "plot_model(gan_model, to_file='gan_model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "odwgONlQdG7I"
   },
   "outputs": [],
   "source": [
    "# select a batch of random samples, returns images and target\n",
    "def generate_real_samples(dataset, n_samples, patch_shape):\n",
    "\t# unpack dataset\n",
    "\ttrainA, trainB = dataset\n",
    "\t# choose random instances\n",
    "\tix = np.random.randint(0, trainA.shape[0], n_samples)\n",
    "\t# retrieve selected images\n",
    "\tX1, X2 = trainA[ix], trainB[ix]\n",
    "\t# generate 'real' class labels (1)\n",
    "\ty = np.ones((n_samples, patch_shape, patch_shape, 1))\n",
    "\treturn [X1, X2], y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oGSloojddUQP"
   },
   "outputs": [],
   "source": [
    "# generate a batch of images, returns images and targets\n",
    "def generate_fake_samples(g_model, samples, patch_shape):\n",
    "\t# generate fake instance\n",
    "\tX = g_model.predict(samples)\n",
    "\t# create 'fake' class labels (0)\n",
    "\ty = np.zeros((len(X), patch_shape, patch_shape, 1))\n",
    "\treturn X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nsASKp0gE69l"
   },
   "source": [
    "# 5. Train GAN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGkH45NIdQ31"
   },
   "outputs": [],
   "source": [
    "# train pix2pix models\n",
    "def train(d_model, g_model, gan_model, dataset, n_epochs=100, n_batch=1, n_patch=16):\n",
    "\t# unpack dataset\n",
    "\ttrainA, trainB = dataset\n",
    "\t# calculate the number of batches per training epoch\n",
    "\tbat_per_epo = int(len(trainA) / n_batch)\n",
    "\t# calculate the number of training iterations\n",
    "\tn_steps = bat_per_epo * n_epochs\n",
    "\t# manually enumerate epochs\n",
    "\tfor i in range(n_steps):\n",
    "\t\t# select a batch of real samples\n",
    "\t\t[X_realA, X_realB], y_real = generate_real_samples(dataset, n_batch, n_patch)\n",
    "\t\t# generate a batch of fake samples\n",
    "\t\tX_fakeB, y_fake = generate_fake_samples(g_model, X_realA, n_patch)\n",
    "\t\t# update discriminator for real samples\n",
    "\t\td_loss1 = d_model.train_on_batch([X_realA, X_realB], y_real)\n",
    "\t\t# update discriminator for generated samples\n",
    "\t\td_loss2 = d_model.train_on_batch([X_realA, X_fakeB], y_fake)\n",
    "\t\t# update the generator\n",
    "\t\tg_loss, _, _ = gan_model.train_on_batch(X_realA, [y_real, X_realB])\n",
    "\t\t# summarize performance\n",
    "\t\tprint('>%d / %d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1, n_steps, d_loss1, d_loss2, g_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQggoEybdtms",
    "outputId": "6e743fef-8f58-4fb1-ec60-92c1a94a867d"
   },
   "outputs": [],
   "source": [
    "dataset = (train_x, train_x_px)\n",
    "a, b = dataset\n",
    "a.shape, b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "35db0_k6dkU7",
    "outputId": "5a3bd6f9-b5ec-4115-b4a3-62ec6f944a3a"
   },
   "outputs": [],
   "source": [
    "# train model\n",
    "train(d_model, g_model, gan_model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kOKa-DIteEsS"
   },
   "outputs": [],
   "source": [
    "d_model.save('GAN_Models/d_model.h5')\n",
    "g_model.save('GAN_Models/g_model.h5')\n",
    "gan_model.save('GAN_Models/gan_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjbmentmE-fn"
   },
   "source": [
    "# 6. Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7IINUAFFrZI"
   },
   "outputs": [],
   "source": [
    "def display_image_in_actual_size(img, type):\n",
    "\n",
    "    dpi = mpl.rcParams['figure.dpi']\n",
    "    im_data = img\n",
    "    height, width, depth = im_data.shape\n",
    "\n",
    "    # What size does the figure need to be in inches to fit the image?\n",
    "    figsize = 3*width / float(dpi), 3*height / float(dpi)\n",
    "\n",
    "    # Create a figure of the right size with one axes that takes up the full figure\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_axes([0, 0, 1, 1])\n",
    "\n",
    "    # Hide spines, ticks, etc.\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Display the image.\n",
    "    ax.imshow(im_data, cmap='gray')\n",
    "    plt.title(type)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9j-Hd4IFU0z"
   },
   "outputs": [],
   "source": [
    "def evaluate(img, model):\n",
    "    f, ax = plt.subplots(1, 2)\n",
    "    ax[0].set_title('Input Image')\n",
    "    ax[1].set_title('Output Image')\n",
    "\n",
    "    test_img = np.array(pixelate_image(img))\n",
    "    ax[0].imshow(test_img)\n",
    "    test_img = np.expand_dims(test_img, axis=0)\n",
    "    pred = g_model.predict(test_img)\n",
    "    pred = np.squeeze(pred, axis=0)\n",
    "    ax[1].imshow(pred)\n",
    "\n",
    "    # print(f\"Diff = {pred - test_img}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJu79fDKF259"
   },
   "outputs": [],
   "source": [
    "with open('GAN_Models/img_array.pickle', 'rb') as f:\n",
    "    img_array = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p4zmpQgqGDEl",
    "outputId": "e2abc9fe-a506-4b7d-e845-f20bcdc3fb02"
   },
   "outputs": [],
   "source": [
    "len(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rxq6mVhWGLey",
    "outputId": "95215d8c-cf13-4f8f-f553-1095d910cacf"
   },
   "outputs": [],
   "source": [
    "d_model = keras.models.load_model('GAN_Models/d_model_kaggle.h5')\n",
    "g_model = keras.models.load_model('GAN_Models/g_model_kaggle.h5')\n",
    "gan_model = keras.models.load_model('GAN_Models/gan_model_kaggle.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ux6wD-DNGqbb"
   },
   "source": [
    "## Images in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "EmevmAyQqRhz",
    "outputId": "745ec8dc-da9e-40a1-c157-2a1f61fd29fd"
   },
   "outputs": [],
   "source": [
    "evaluate(img_array[123], g_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "gPNAHFmbWxK3",
    "outputId": "4bd0402f-51ed-4ff7-ba0a-96c3daf68c39"
   },
   "outputs": [],
   "source": [
    "evaluate(img_array[999], g_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "iczWFKiMqYJS",
    "outputId": "a6a68d36-8311-49ae-af25-41c8c2e4fafe"
   },
   "outputs": [],
   "source": [
    "evaluate(img_array[500], g_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "XxfNlg7NqxFJ",
    "outputId": "1315b637-903e-4498-ebe7-602496acb466"
   },
   "outputs": [],
   "source": [
    "evaluate(img_array[870], g_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UuQiOTycGuFv"
   },
   "source": [
    "## Images NOT in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsqvED6yGvwu"
   },
   "outputs": [],
   "source": [
    "def read(path):\n",
    "  img = image.load_img(path, target_size=(256,256,3))\n",
    "  img = image.img_to_array(img)\n",
    "  img = img/255.\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 233
    },
    "id": "l1DSxj-nX4RM",
    "outputId": "526ff4a3-5879-42ac-c47f-531446b728fa"
   },
   "outputs": [],
   "source": [
    "test1 = read('Test_Images/test1.jpg')\n",
    "evaluate(test1, g_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "nOOUpdulYOxr",
    "outputId": "b43bff76-2ca4-467e-8889-450f2527e9fd"
   },
   "outputs": [],
   "source": [
    "test2 = read('Test_Images/test2.jpg')\n",
    "evaluate(test2, g_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "pPtVc1IxYQIN",
    "outputId": "a22b35d1-2d13-449c-aba8-5385b1dcb6f6"
   },
   "outputs": [],
   "source": [
    "test3 = read('Test_Images/test3.jpg')\n",
    "evaluate(test3, g_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IkN9KU5Syx76"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Image_Upscaling_GANs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
